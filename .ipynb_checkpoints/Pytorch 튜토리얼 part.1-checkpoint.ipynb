{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 개좆밥이 조금이라도 더 이해해보자고 쓰는 Pytorch 튜토리얼 1\n",
    "워낙에 아는게 없기 때문에 쓸데없어 보이는 별의별거 다 들어가는 튜토리얼\n",
    "\n",
    "### Pytorch는 무엇인가?\n",
    "pyTorch 공식 튜토리얼 https://pytorch.org/tutorials/ 에서는, PyTorch에 대해 다음과 같이 설명하고 있다.\n",
    "\n",
    "PyTorch는 파이썬 기반의 과학 컴퓨팅 패키지로 두 집단을 대상으로 합니다.\n",
    "   * NumPy를 대체하고 GPU의 힘을 사용\n",
    "   * 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플래폼\n",
    "   \n",
    "...라고 설명되어 있다. 그러나 이 설명만으로는 기존에 Torch를 사용해보지 않았거나 딥러닝을 이제 막 공부하기 시작한 사람들에게는<br>\n",
    "충분하지 않은 설명이라고 생각되어 추가적으로 Torch에 대해 설명해보자면,\n",
    "\n",
    "## Torch\n",
    "Torch는 GPU를 사용하면서 객체지향적으로 모델을 만드는 Lua를 사용하는 딥러닝 라이브러리이다.<br>\n",
    "Torch는 다음과 같은 특징을 갖고 있다.\n",
    "   * Python보다 빠름. Just in time compilation(JIT 컴파일, 동적번역으로 프로그램을 실행하는 시점에 기계어로 번역하는 것) 때문에.\n",
    "   * Luarocks로 Python의 pip처럼 lua package를 설치   \n",
    "   * 페이스북, 딥마인드, 트위터 등 여러회사에서 사용\n",
    "   * Numpy처럼 다룰 수 있음\n",
    "   * 모듈안에 자신의 코드를 만들어서 사용가능\n",
    "   * 네트워크 구조를 짜는 것이 아닌, 텐서와 텐서를 연결하는 node를 만들어서 구현\n",
    "   \n",
    "과 같은 특징을 갖고 있다. 다음과 같은 특징들에서 나오는 Torch의 장점으로는 \n",
    "   * 결합시키기 쉬운 많은 모듈러 조각을 만들 수 있음\n",
    "   * 다른 딥러닝 라이브러리와 비교해서 GPU를 이용한 코딩이 매우 쉬움\n",
    "   * 대부분의 참조하는 라이브러리 코드가 Lua에 있으며, 읽기가 쉬움\n",
    "   * 많은 사전 훈련된 모델\n",
    "   \n",
    "과 같은 장점들이 있다. 반면 단점으로는 다음과 같은 단점들이 있는데,\n",
    "   * **Lua**\n",
    "   * Caffe보다 플러그 앤 플레이가 적음\n",
    "   * RNN에는 적합하지 않음\n",
    "   \n",
    "이 있다. Torch는 이전부터 좋은 딥러닝 라이브러리로 평가 받았지만 Lua를 사용한다는 것이 문제가 되었다. <br>\n",
    "물론 Lua를 배워서라도 하려는 사람들이 많을 정도로 좋은 라이브러리지만, 강조했듯이 **Lua**의 진입장벽이 가장 큰 단점으로 작용했고,<br>\n",
    "이 Torch 라이브러리를 Python으로 컨버팅하여 만든것이 바로 PyTorch다.<br>\n",
    "여기에 Pytorch는 Python으로 컨버팅을 하게 되면서 Python의 다른 계산 모듈들을 사용할 수 있게 되는 더욱 큰 장점을 가지게 되었다.\n",
    "~~http://tmmse.xyz/2016/02/25/choosing-deep-learning-libraries/ 참조~~\n",
    "\n",
    "### PyTorch와 Tensorflow의 차이\n",
    "딥러닝 공부를 시작하면서 많은 사람들이 Pytorch와 Tensorflow 둘 중 에서 무엇으로 시작할지 고민을 하고 있고, 가장 많이 사용되는 두가지 딥러닝 라이브러리의 차이를 알기 위해 두 라이브러리의 차이점을 찾아보게 되었다.<br>\n",
    "\n",
    "가장 큰 차이점으로는 Tensorflow는 static하고, Pytorch는 dynamic하다는 것이다.<br>\n",
    "Tensorflow의 경우에는 그래프 구조를 먼저 그려놓고, 그것을 fix해서 데이터가 그 안에서 흐르게 되는 구조로 간단히 요약하면<br>\n",
    "모델을 설정하고 데이터를 돌리는 2가지의 단계로 명확히 구분지어져 있다.<br>\n",
    "해당 구조의 단점은 런타임에서 사용자가 인터렉티브하게 개입하거나 중간에 구조가 바뀌던가 하는 조정이 불가능하다는 것이다.<br><br>\n",
    "\n",
    "반면에 Pytorch의 경우에는 Tensorflow보다 훨씬 늦게 나왔는데, (Torch를 기준으로 1년정도, Pytorch의 경우 2년 정도)<br>\n",
    "나중에 나온 라이브러리인 만큼 Tensorflow의 단점을 수정하고 나오게 되면서 Tensorflow의 단점인 static한 구조를 수정해서 나오게 되었다.<br>\n",
    "\n",
    "또 다른 차이점으로는 Pytorch는 기존에 우리가 하듯이 runtime debugging을 할 수 있지만, Tensorflow는 실행중 중간에 개입하여 디버깅하기가<br>굉장히 힘들다. (tfdbg라는 툴을 이용하면 가능하지만, 처음부터 지원이 되는것과는 비교하기 힘들다.)<br>\n",
    "\n",
    "Tensorflow의 장점으로는 visuallization, 시각화가 있다. Tensorflow의 TensorBoard는 시각화쪽에서 굉장히 강력한 성능을 제공하고 있다.<br>\n",
    "반면에 Pytorch는 공식적인 시각화 툴이 없다. (Visdom이라는 툴이 최근에 제공되기 시작함)<br>\n",
    "\n",
    "또한 Tensorflow의 사용자 커뮤니티가 Pytorch의 사용자 커뮤니티보다 훨씬 크다는 것도 Tensorflow의 큰 장점이다.<br>\n",
    "~~당장 facebook 그룹의 인원부터 Tensorflow KR의 사용자수는 약 4만명인데 비해, Pytorch KR의 사용자는 약 5500명으로 큰차이가 난다.~~<br>\n",
    "그만큼 Tensorflow쪽이 코드를 찾거나, 질문과 답을 찾거나 정보를 구하기가 Pytorch에 비해 훨씬 쉬우며 이로인해 Tensorflow가<br>\n",
    "Pytorch보다 쉽게 느껴지게 된다.<br>\n",
    "~~물론 Pytorch도 기본적인 정보와 커뮤니티는 존재하지만, Tensorflow의 커뮤니티보다 적은건 사실이다.~~<br>\n",
    "\n",
    "Low, High-Level적인 측면에서는 Tensorflow는 점점 라이브러리가 커지면서 거의 C 수준으로 low-Level까지 컨트롤 할 수 있게 컨트롤 할 수 있도록\n",
    "라이브러리가 많이 커졌다.<br>\n",
    "반면 PyTorch는 딥러닝 자체의 구조만을 만들고 실행시키는 것에 관련해서만 집중되어 있다.<br>\n",
    "이로인해 요소, 변수가 많은 실제 업무에서 쓰일 용도로는 Tensorflow가 조금 더 좋고, 공부 또는 개인적인 용도로 사용하는데는 PyTorch가 조금 더 좋다.<br>\n",
    "\n",
    "~~위에 차이점 표 첨부해야될듯~~\n",
    "~~http://bitly.kr/9YDB http://bitly.kr/9YDB 참조~~<br>\n",
    "\n",
    "## Pytorch 시작하기\n",
    "\n",
    "### Tensors\n",
    "\n",
    "#### Tensor는 무엇인가\n",
    "Tensor는 수학과 과학에서 선형 관계를 나타내는 기하적 대상이다. 텐서에 대하여 쉽게 설명을 해보자면,<br>\n",
    "<br>\n",
    "A가 자신의 집으로 가는 방법을 표현한다고 할 경우, A가 \"내 집은 여기서 3km 떨어져 있어\"에서 3km는 스칼라가 되고,<br>\n",
    "\"내 집으로 가려면 여기서 2km를 북쪽으로 간 후 1km 동쪽으로가서 3계단 올라가야 해.\"라는 답으로 3개의 공간 성분을 가진 3차원 벡터가 만들어지는<br> 것을 확인 할 수가 있다.<br>\n",
    "\n",
    "여기서 벡터에 스칼라를 곱하는 경우 v = au 와 같은식으로 쉽게 곱할 수 있다.<br>\n",
    "그런데 방향과 크기를 동시에 바꾸려면 단순히 스칼라를 곱해서는 안된다. 다른 벡터와의 외적 역시 곱하면 무조건 직각으로만 바뀌기 때문에 안된다.<br>\n",
    "따라서 **한번에 방향과 크기를 동시에 바꿔줄 것**이 필요하게 되고, 이를 위해 백터를 복합적으로 연결시킨 구조를 **Tensor**라고 한다.\n",
    "\n",
    "#### Pytorch에서의 Tensor 선언\n",
    "    Pytorch의 Tensor는 NumPy의 ndarray와 유사할뿐만 아니라, GPU를 사용한 연산 가속도 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-19 *\n",
      "       [[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.6109,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 초기화 되지 않은 5x3 행렬을 생성한다.\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7750,  0.1933,  0.3376],\n",
      "        [ 0.6186,  0.0879,  0.2701],\n",
      "        [ 0.8082,  0.4008,  0.5986],\n",
      "        [ 0.8133,  0.8259,  0.9688],\n",
      "        [ 0.5040,  0.7888,  0.9928]])\n"
     ]
    }
   ],
   "source": [
    "# 무작위로 초기화된 5x3 행렬을 생성한다.\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 행렬의 크기를 구한다.\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor의 연산\n",
    "    PyTorch는 연산을 위한 여러가지 문법을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7750,  0.1933,  0.3376],\n",
      "        [ 0.6186,  0.0879,  0.2701],\n",
      "        [ 0.8082,  0.4008,  0.5986],\n",
      "        [ 0.8133,  0.8259,  0.9688],\n",
      "        [ 0.5040,  0.7888,  0.9928]])\n",
      "tensor([[ 0.5452,  0.6278,  0.0987],\n",
      "        [ 0.1394,  0.8774,  0.7473],\n",
      "        [ 0.8053,  0.4184,  0.9333],\n",
      "        [ 0.9985,  0.8164,  0.2633],\n",
      "        [ 0.6394,  0.1485,  0.8014]])\n",
      "tensor([[ 1.3202,  0.8211,  0.4363],\n",
      "        [ 0.7580,  0.9653,  1.0174],\n",
      "        [ 1.6134,  0.8192,  1.5319],\n",
      "        [ 1.8118,  1.6423,  1.2321],\n",
      "        [ 1.1434,  0.9373,  1.7941]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "# 여러 덧셈 문법\n",
    "print (x)\n",
    "print (y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2589,  0.6229,  0.9439],\n",
      "        [ 1.3883,  0.2435,  0.7242],\n",
      "        [ 1.4421,  0.9395,  1.4655],\n",
      "        [ 0.9990,  1.6243,  1.9219],\n",
      "        [ 1.4742,  1.0063,  1.1258]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2589,  0.6229,  0.9439],\n",
      "        [ 1.3883,  0.2435,  0.7242],\n",
      "        [ 1.4421,  0.9395,  1.4655],\n",
      "        [ 0.9990,  1.6243,  1.9219],\n",
      "        [ 1.4742,  1.0063,  1.1258]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈 결과를 텐서 인자로 제공\n",
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2589,  0.6229,  0.9439],\n",
      "        [ 1.3883,  0.2435,  0.7242],\n",
      "        [ 1.4421,  0.9395,  1.4655],\n",
      "        [ 0.9990,  1.6243,  1.9219],\n",
      "        [ 1.4742,  1.0063,  1.1258]])\n"
     ]
    }
   ],
   "source": [
    "# y에 x 더하기\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1933,  0.0879,  0.4008,  0.8259,  0.7888])\n"
     ]
    }
   ],
   "source": [
    "# Numpy의 인덱싱 표기방법을 사용 할 수도 있음\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 크기(size)나 모양(shape)을 변경하고 싶을 때, torch.view 를 사용한다.\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # 사이즈가 -1인 경우 다른 차원들을 사용하여 유추합니다.\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy 변환(Bridge)\n",
    "    Torch Tensor를 NumPy 배열(array)로 변환하거나, 그 반대로 변하게 하는 것은 매우 쉽다.\n",
    "    Torch Tensor와 NumPy 배열은 저장 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.,  1.,  1.,  1.])\n",
      "\n",
      "\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor 선언\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(\"\\n\")\n",
    "# Numpy array 선언\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Numpy array와 Torch Tensor사이의 연산\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(\"\\n\") # 한쪽에만 더해주었는데 같이 변하는 걸 확인 - 저장공간을 공유함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 반대로 np배열의 값을 변화시켜도 torch tensor의 값도 변한다.\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors\n",
    "    .to 메소드를 사용하여 Tensor를 GPU 상으로 옮길 수 있다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6398,  2.4916,  0.8794,  0.2813],\n",
      "        [ 0.5152,  1.0626, -0.8613, -1.9972],\n",
      "        [-0.1854,  4.2127,  1.3663,  0.9738],\n",
      "        [ 0.4678,  0.6055,  0.6897,  0.0511]], device='cuda:0')\n",
      "tensor([[ 0.6398,  2.4916,  0.8794,  0.2813],\n",
      "        [ 0.5152,  1.0626, -0.8613, -1.9972],\n",
      "        [-0.1854,  4.2127,  1.3663,  0.9738],\n",
      "        [ 0.4678,  0.6055,  0.6897,  0.0511]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 이 코드는 CUDA가 사용 가능한 환경에서만 실행 가능하다.\n",
    "# ``torch.device`` 를 사용하여 tensor를 GPU로 이동하는 예제\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # CUDA 장치 객체(Device Object)로\n",
    "    y = torch.ones_like(x, device=device)  # GPU 상에 바로(directly) tensor를 생성하거나\n",
    "    x = x.to(device)                       # 단지 ``.to(\"cuda\")`` 라고만 작성하면 됨\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 는 dtype도 함께 변경함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망\n",
    "신경망이란\n",
    "\n",
    "## Pytorch에서의 신경망\n",
    "신경망은 torch.nn 패키지를 사용하여 생성할 수 있습니다.\n",
    "\n",
    "지금까지 autograd 를 살펴봤는데요, nn 은 모델을 정의하고 미분하는데 autograd 를 사용합니다.<br>\n",
    "nn.Module 은 계층(layer)과 output 을 반환하는 forward(input) 메서드를 포함하고 있습니다.<br>\n",
    "숫자 이미지를 분류하는 신경망을 예제로 살펴보겠습니다<br>\n",
    "이는 간단한 피드-포워드 네트워크(Feed-forward network)이다. 입력(input)을 받아 여러 계층에 차례로 전달한 후,<br>\n",
    "최종 출력(output)을 제공하게 된다.\n",
    "\n",
    "신경망의 학습 과정은 대체로 다음과 같다.\n",
    "   * 학습 가능한 매개변수(또는 가중치(weight))를 갖는 신경망을 정의합니다.\n",
    "   * 데이터셋(dataset) 입력을 반복합니다.\n",
    "   * 입력을 신경망에서 처리합니다.\n",
    "   * 손실(loss; 출력이 정답으로부터 얼마나 떨어져있는지)을 계산합니다.\n",
    "   * 변화도(gradient)를 신경망의 매개변수들에 역으로 전파합니다.\n",
    "   * 신경망의 가중치를 갱신합니다. 일반적으로 다음과 같은 간단한 규칙을 사용합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch에서 신경망 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward 함수만 정의하고 나면, (변화도를 계산하는)backward 함수는 autograd 를 사용하여 자동으로 정의된다.<br>\n",
    "forward 함수에서는 어떠한 Tensor 연산을 사용해도 된다.<br>\n",
    "\n",
    "모델의 학습 가능한 매개변수들은 net.parameters()에 의해 반환된다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 32x32 입력값을 넣어보겠습니다. 이 신경망에 MNIST 데이터셋을 사용하기 위해서는, 데이터셋의 이미지를 32x32로 크기를 변경해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0439, -0.0381,  0.1588,  0.0189,  0.0476, -0.1660,  0.0868,\n",
      "         -0.1205,  0.2261, -0.1901]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 매개변수의 변화도 버퍼(gradient buffer)를 0으로 설정하고, 무작위 값으로 역전파를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.nn 은 미니 배치(mini-batch)만 지원합니다. torch.nn 패키지 전체는 하나의 샘플이 아닌, 샘플들의 미니배치만을 입력으로 받습니다.\n",
    "    예를 들어, nnConv2D 는 nSamples x nChannels x Height x Width 의 4차원 Tensor를 입력으로 합니다.\n",
    "    만약 하나의 샘플만 있다면, input.unsqueeze(0) 을 사용해서 가짜 차원을 추가합니다.\n",
    "    \n",
    "    미니 배치란"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 (Loss Function)\n",
    "\n",
    "손실 함수란?\n",
    "\n",
    "\n",
    "\n",
    "손실 함수는 (output, target)을 한 쌍(pair)의 입력으로 받아, 출력(output)이 정답(target)으로부터 얼마나<br>\n",
    "떨어져있는지를 추정하는 값을 계산합니다.\n",
    "\n",
    "nn 패키지에는 여러가지의 손실 함수들 이 존재한다. 간단한 손실 함수로는 출력과 대상간의 평균자승오차(mean-squared error)를<br>\n",
    "계산하는 nn.MSEloss 가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.6089)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.arange(1, 11)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".grad_fn 속성을 사용하여 loss 를 역방향에서 따라가다보면, 다음과 같은 모습의 연산 그래프를 볼 수 있다.\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d<br>\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear<br>\n",
    "          -> MSELoss<br>\n",
    "          -> loss<br>\n",
    "      \n",
    "따라서, loss.backward() 를 실행할 때, 전체 그래프는 손실(loss)에 대해 미분되며, 그래프 내의 requires_grad=True 인 모든 Tensor는<br>\n",
    "변화도(Gradient)가 누적된 .grad Tensor를 갖게 된다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000018C83A533C8>\n",
      "<AddmmBackward object at 0x0000018C83A534E0>\n",
      "<ExpandBackward object at 0x0000018C83A533C8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파\n",
    "\n",
    "역전파란?\n",
    "\n",
    "오차(error)를 역전파하기 위해 할 일은 loss.backward() 이 전부다. 이 때 기존 변화도를 지우는 작업이 필요한데,<br>\n",
    "그렇지 않으면 변화도가 기존의 것에 누적된다.<br>\n",
    "\n",
    "이제 loss.backward() 를 호출하여 역전파 전과 후에 conv1의 bias gradient를 살펴보면,<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0974, -0.0964,  0.0174, -0.0673,  0.1015,  0.0734])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치\n",
    "가중치란?\n",
    "    \n",
    "실제로 많이 사용되는 가장 단순한 갱신 규칙은 확률적 경사하강법(SGD; Stochastic Gradient Descent)입니다:\n",
    "\n",
    "    가중치(wiehgt) = 가중치(weight) - 학습율(learning rate) * 변화도(gradient)    \n",
    "간단한 Python 코드로 이를 구현해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나, 신경망을 구성할 때 SGD, Nesterov-SGD, Adam, RMSProp 등과 같은 다양한 갱신 규칙을 사용하고 싶을 수 있다.<br>\n",
    "이를 위해서 torch.optim 라는 작은 패키지에 이러한 방법들을 모두 구현되어 있다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Optimizer를 생성합니다.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 과정(training loop)에서는 다음과 같습니다:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer.zero_grad() 를 사용하여 수동으로 변화도 버퍼를 0으로 설정하는 것에 유의하세요. 이는 역전파(Backprop) 섹션에서 설명한 것처럼 변화도가 누적되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
